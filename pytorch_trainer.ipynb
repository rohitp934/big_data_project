{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- PyTorch Fully Convolutional Network Trainer ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modal import App, Image, Volume, gpu\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create modal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = App(\"trainer-imgoingtokillmyself\")\n",
    "volume = Volume.from_name('bigdata')\n",
    "img = Image.debian_slim().pip_install(\"numpy\", \"scikit-learn\", \"glob2\", \"lightning\", \"torchvision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUTS = 3\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```one_hot_encode``` is a function that takes a tensor of labels and returns a tensor of one-hot encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    # Ensure labels are a PyTorch tensor\n",
    "    if isinstance(labels, np.ndarray):\n",
    "        labels = torch.from_numpy(labels)\n",
    "        \n",
    "    # Ensure labels are of type torch.long, required for one_hot function\n",
    "    labels = labels.long()\n",
    "    \n",
    "    # Apply one-hot encoding\n",
    "    one_hot = torch.nn.functional.one_hot(labels[:,:,:,0], num_classes=num_classes)\n",
    "    \n",
    "    # one_hot returns a tensor of shape (batch, height, width, num_classes) directly\n",
    "    return one_hot.permute(0, 3, 1, 2).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to load data paths - ```load_data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, val_size=0.2, test_size=0.1):\n",
    "    file_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.npz')]\n",
    "    print(f\"Found files: {file_paths}\")\n",
    "    # file_paths = file_paths[:5]\n",
    "    train_val_paths, test_paths = train_test_split(file_paths, test_size=test_size, random_state=42)\n",
    "    train_paths, val_paths = train_test_split(train_val_paths, test_size=val_size, random_state=42)\n",
    "    return train_paths, val_paths, test_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compute mean and standard deviation for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(images):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for img in images:\n",
    "        mean += img.mean(axis = (0, 1, 2), keepdims=True)\n",
    "        std += img.std(axis = (0, 1, 2), keepdims=True)\n",
    "    \n",
    "    mean /= images.shape[0]\n",
    "    std /= images.shape[0]\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset from numpy archives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data generated from the Apache Beam pipeline writes numpy zip files, we create a PyTorch ```Dataset``` to read and index this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZDataset(Dataset):\n",
    "    def __init__(self, image_data, labels, transform=None):\n",
    "        self.image_data = image_data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.image_data[idx].astype(np.float32)\n",
    "        labels = self.labels[idx]\n",
    "        # labels = labels.long().squeeze()\n",
    "        if self.transform:\n",
    "            inputs = self.transform(inputs)\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ```Dataset``` assumes that the images and labels are in PyTorch's preferred dimensions of ```(batch, channels, height, width)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model arhitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandCoverModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(NUM_INPUTS, 32, kernel_size=(5,5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(32, 16, kernel_size=(5,5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, NUM_CLASSES, kernel_size = (1,1))\n",
    "        )\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0, 3, 1, 2)\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        val_loss = self.loss_fn(outputs, labels)\n",
    "        self.log('val_loss', val_loss, on_epoch=True, prog_bar=True)\n",
    "        return {'val_loss': val_loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        test_loss = self.loss_fn(outputs, labels)\n",
    "        self.log('test_loss', test_loss, on_epoch=True, prog_bar=True)\n",
    "        return {'test_loss': test_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=512, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=512, shuffle=False, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=512, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```LandCoverModel``` is an example of a fully convolutional network (FCN). Each of the embedded images have 3 channels which correspond to the ```NUM_INPUTS``` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modal functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be trained on the modal platform which provides cloud GPUs for training and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.function(image=img, timeout=60*60*24, volumes={\"/vol\": volume}, gpu=gpu.A10G(count=1), _allow_background_volume_commits=True)\n",
    "def train_model():\n",
    "    data_dir = '/vol/actual/npz'\n",
    "    train_paths, val_paths, test_paths = load_data(data_dir)\n",
    "\n",
    "    model = LandCoverModel()\n",
    "    train_images = np.concatenate([np.load(f)['inputs'] for f in train_paths], axis=0)\n",
    "    train_labels = one_hot_encode(np.concatenate([np.load(f)['labels'] for f in train_paths], axis=0), NUM_CLASSES)\n",
    "\n",
    "    val_images = np.concatenate([np.load(f)['inputs'] for f in val_paths], axis=0)\n",
    "    val_labels = one_hot_encode(np.concatenate([np.load(f)['labels'] for f in val_paths], axis=0), NUM_CLASSES)\n",
    "\n",
    "    test_images = np.concatenate([np.load(f)['inputs'] for f in test_paths], axis=0)\n",
    "    test_labels = one_hot_encode(np.concatenate([np.load(f)['labels'] for f in test_paths], axis=0), NUM_CLASSES)\n",
    "\n",
    "\n",
    "    mean, std = compute_mean_std(train_images)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    model.train_dataset = NPZDataset(train_images, train_labels, transform=transform)\n",
    "    model.val_dataset = NPZDataset(val_images, val_labels, transform=transform)\n",
    "    model.test_dataset = NPZDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath='checkpoints/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        auto_insert_metric_name=False\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        accelerator=\"gpu\",\n",
    "        devices=-1,\n",
    "    )\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an entrypoint for the modal server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.local_entrypoint()\n",
    "def main():\n",
    "    train_model.remote()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
